# HE2-IA-PARCIAL-3---
Este proyecto implementa un sistema RAG completo para recomendar y explicar recetas en espaÃ±ol. Usa sentence-transformers como encoder para recuperar recetas relevantes desde un dataset real de Hugging Face, y un modelo generativo open-source como decoder para producir explicaciones claras, paso a paso y adaptadas a la consulta del usuario.
ğŸ“˜ README â€” RAG de Recetas en EspaÃ±ol
ğŸ¥˜ Asistente de Cocina con Retrieval-Augmented Generation (RAG)

Este proyecto implementa un asistente de recetas en espaÃ±ol usando la arquitectura RAG (Retrieval-Augmented Generation).

El sistema:

Recupera recetas relevantes segÃºn la consulta del usuario usando un encoder basado en Transformer.

Genera una explicaciÃ³n paso a paso usando un modelo generativo open-source.

Ejemplo de consulta:

â€œTengo arroz y huevo. Quiero algo rÃ¡pido para el desayuno y sin horno.â€

Este pipeline demuestra, en la prÃ¡ctica, cÃ³mo funcionan los componentes clave de NLP vistos en clase: embeddings, Transformers, recuperaciÃ³n semÃ¡ntica y modelos generativos.

ğŸš€ TecnologÃ­as principales
ğŸ”¹ Encoder (Retriever)

Modelo: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

Tipo: Transformer encoder-only

Uso:

Convierte recetas y consultas en embeddings semÃ¡nticos

Permite buscar recetas similares usando similitud de coseno

ğŸ”¹ Vector Store

Construido en memoria usando numpy

Contiene:

Embeddings de recetas

Metadatos (nombre, ingredientes, instrucciones)

Permite recuperaciÃ³n rÃ¡pida sin base de datos externa

ğŸ”¹ Decoder (Generative Model)

Modelo recomendado:

TinyLlama/TinyLlama-1.1B-Chat-v1.0 (ligero, open-source y compatible con Colab)

Tipo: Transformer decoder-only

Genera:

explicaciÃ³n paso a paso

recomendaciones adaptadas

lenguaje simple apto para principiantes

ğŸ”¹ Dataset

Hugging Face: m3hrdadfi/recipe_nlg_lite

Contiene:

nombres

ingredientes

pasos detallados

descripciones

Se utiliza un subconjunto (~300 recetas) para experimentaciÃ³n rÃ¡pida
